{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word-suggest.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1LdeKrQWvHHl6jvkcLwzbF308q8bneKDw","authorship_tag":"ABX9TyNbNn0G7N+HG1dL7mHTkfbO"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EnNuauAeSv1N"},"source":["#Word Suggestions"]},{"cell_type":"code","metadata":{"id":"TrKMgjPLz4_U"},"source":["%tensorflow_version 2.x\r\n","import tensorflow as tf\r\n","import string\r\n","import requests"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZrD1TrCX0UPt"},"source":["# using shakespeare writings for training our model \r\n","response = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QGsXkE1TTsQX"},"source":["###Text Preprocessing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"bEc7y72d0fgV","executionInfo":{"status":"ok","timestamp":1608116696490,"user_tz":-330,"elapsed":2304,"user":{"displayName":"Jaswanth Batturi","photoUrl":"","userId":"05545196213983093297"}},"outputId":"6b16e8ce-5810-4397-d0fe-b8e7eaba2920"},"source":["data = response.text.split('\\n')\r\n","data[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'This is the 100th Etext file presented by Project Gutenberg, and'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Os5Geq9x0yDs","executionInfo":{"status":"ok","timestamp":1608116696493,"user_tz":-330,"elapsed":2286,"user":{"displayName":"Jaswanth Batturi","photoUrl":"","userId":"05545196213983093297"}},"outputId":"384c0b58-7ebb-4326-f5d8-7ebc942677b3"},"source":["data = data[253:]\r\n","data[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'  From fairest creatures we desire increase,'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"_XfpSR0j0zWM"},"source":["data = \" \".join(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6W-Bb9V019x","executionInfo":{"status":"ok","timestamp":1608116697117,"user_tz":-330,"elapsed":2880,"user":{"displayName":"Jaswanth Batturi","photoUrl":"","userId":"05545196213983093297"}},"outputId":"d8a00702-3c18-4fe6-a37c-21e1e3588933"},"source":["# cleaning the text\r\n","def clean_text(doc):\r\n","  tokens = doc.split()\r\n","  table = str.maketrans('', '', string.punctuation)\r\n","  tokens = [w.translate(table) for w in tokens]\r\n","  tokens = [word for word in tokens if word.isalpha()]\r\n","  tokens = [word.lower() for word in tokens]\r\n","  return tokens\r\n","\r\n","tokens = clean_text(data)\r\n","print(tokens[:50])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['from', 'fairest', 'creatures', 'we', 'desire', 'increase', 'that', 'thereby', 'beautys', 'rose', 'might', 'never', 'die', 'but', 'as', 'the', 'riper', 'should', 'by', 'time', 'decease', 'his', 'tender', 'heir', 'might', 'bear', 'his', 'memory', 'but', 'thou', 'contracted', 'to', 'thine', 'own', 'bright', 'eyes', 'feedst', 'thy', 'lights', 'flame', 'with', 'selfsubstantial', 'fuel', 'making', 'a', 'famine', 'where', 'abundance', 'lies', 'thy']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcvZMBk71DJY","executionInfo":{"status":"ok","timestamp":1608116697119,"user_tz":-330,"elapsed":2867,"user":{"displayName":"Jaswanth Batturi","photoUrl":"","userId":"05545196213983093297"}},"outputId":"28c4f1f9-51b8-433f-d8a2-6f458192acb9"},"source":["length = 10 + 1  # sequence length\r\n","lines = []\r\n","\r\n","# creating the sequence of lines\r\n","for i in range(length, len(tokens)):\r\n","  seq = tokens[i-length:i]\r\n","  line = ' '.join(seq)\r\n","  lines.append(line)\r\n","  if i > 100000:      # Training on 1 lakh words\r\n","    break\r\n","\r\n","print(len(lines))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["99991\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l9SUAk8D1IIT"},"source":["import numpy as np\r\n","import keras\r\n","from tensorflow.keras.preprocessing.text import Tokenizer\r\n","from tensorflow.keras.utils import to_categorical\r\n","from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.layers import Dense, LSTM, Embedding\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CwpFWVh91Wx8"},"source":["# converting words to numericals using Tokenizer\r\n","tokenizer = Tokenizer()\r\n","tokenizer.fit_on_texts(lines)\r\n","sequences = tokenizer.texts_to_sequences(lines)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVh14sX81ZXt"},"source":["sequences = np.array(sequences)\r\n","X, y = sequences[:, :-1], sequences[:,-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXUKZLJf1Zzn"},"source":["vocab_size = len(tokenizer.word_index) + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BpDAVvzL1cr-"},"source":["# one hot encoding of y\r\n","y = to_categorical(y, num_classes=vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WDsPEpP1fDr"},"source":["seq_length = X.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSjuJoXiT9j3"},"source":["## LSTM model"]},{"cell_type":"code","metadata":{"id":"wba3g1fg1ilN"},"source":["# Layers\r\n","model = Sequential()\r\n","model.add(Embedding(vocab_size, 50, input_length=seq_length))\r\n","model.add(LSTM(100, return_sequences=True))\r\n","model.add(LSTM(100))\r\n","model.add(Dense(100, activation='relu'))\r\n","model.add(Dense(vocab_size, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1WmyVX01kgD"},"source":["model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N73j-WFH1n5f"},"source":["# increase the epochs to get more accuracy\r\n","history = model.fit(X, y, batch_size = 256, epochs = 100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cTYo1J81qeV"},"source":["model.save(\"/content/drive/MyDrive/Colab Notebooks/word-suggest.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4bIGiUI14ET"},"source":["model = keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/word-suggest.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hh0xAYgz14pu"},"source":["# function to generate the next text of words from the given text\r\n","def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\r\n","  \"\"\"\r\n","  seed_text is the input text.\r\n","  n_words is the number of words to be predicted after the input text.\r\n","  \"\"\"\r\n","  text = []\r\n","\r\n","  for _ in range(n_words):\r\n","    encoded = tokenizer.texts_to_sequences([seed_text])[0]\r\n","    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\r\n","\r\n","    y_predicts = np.argsort(np.max(model.predict(encoded), axis=0))[[-1,-2,-3]]\r\n","    y_confidences = np.sort(np.max(model.predict(encoded), axis=0))[[-1,-2,-3]]\r\n","\r\n","    print(\"Suggestions: \", end='')\r\n","    for y_predict in y_predicts:\r\n","      for word, index in tokenizer.word_index.items():\r\n","        if index == y_predict:\r\n","          print(word , end='     ')\r\n","          break\r\n","    print(f\"\\nConfidence:  {y_confidences[0]:.2f}   {y_confidences[1]:.2f}   {y_confidences[2]:.2f}\")\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"KYKqJ1wT-whI","executionInfo":{"status":"ok","timestamp":1608117821878,"user_tz":-330,"elapsed":1191,"user":{"displayName":"Jaswanth Batturi","photoUrl":"","userId":"05545196213983093297"}},"outputId":"e3633174-e50a-425e-a1f3-c78c6497d2bc"},"source":["seed_text = lines[526]\r\n","seed_text"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'was but flowers distilled though they with winter meet leese but'"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n17uF8UA161Y","executionInfo":{"status":"ok","timestamp":1608117824047,"user_tz":-330,"elapsed":1251,"user":{"displayName":"Jaswanth Batturi","photoUrl":"","userId":"05545196213983093297"}},"outputId":"200d4be7-d999-4256-acc0-382eee4d4b69"},"source":["generate_text_seq(model, tokenizer, seq_length, seed_text, 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Suggestions: their     all     the     \n","Confidence:  0.71   0.05   0.03\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"46Z8-8Od9AM4"},"source":[""],"execution_count":null,"outputs":[]}]}